{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d30f83",
   "metadata": {},
   "source": [
    "# Job\n",
    "\n",
    "A `hyrun.job.Job` is a list of tasks (each represented by `hyset.v2.RunSettings`) and (optionally) a list of outputs objects (represented by `hyrun.Result`), together with further information about the job:\n",
    "\n",
    "- `hash` : hash for identifying the job within the workflow and in the database\n",
    "- `db_id`: index of the job in the database\n",
    "- `job_id` : the submission if of the job for identifying the job on the cluster\n",
    "- `status`: status of the job (`str` as defined by slurm)\n",
    "- `job_script`: `hytools.file.File` instance defining commands that are send to the scheduler for execution\n",
    "- `metadata`: a dictionary containing further attributes, which are not used by `hyrun`, e.g., wall-time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c917852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyrun import Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35b1b5",
   "metadata": {},
   "source": [
    "Jobs are initiated by a dict or from (a list of) `hyset.v2.RunSettings`, which represent the tasks of a job.\n",
    "Most of the other parameters, such as `job_script` an `hash` are constructed during `hyrun.init()`.\n",
    "The `job_id` is available once the job has been submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405f2f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job(job_id=None, db_id=None, job_script=None, status=None, hash=None, metadata={'name': 'myjob'}, tasks=[RunSettings(output_file=None, stdout_file=File(name='stdout.out', content=None, path=PosixPath('stdout.out'), host=None, folder=PosixPath('.')), stderr_file=File(name='stderr.out', content=None, path=PosixPath('stderr.out'), host=None, folder=PosixPath('.')), stdin_file=None, files_to_write=[], files_for_restarting=[], files_to_rename=[], files_to_parse=[], files_to_remove=[], files_to_zip=[], files_to_tar=[], files_to_send=[], files_not_to_transfer=[], data_files=[], tar_all_files=False, zip_all_files=False, use_relative_paths=None, overwrite_files=False, conda_env=None, conda_launcher=[], container_image=None, container_executable=None, container_mounts=None, container_type=None, container_launcher=[], container_args=[], work_dir_container=None, work_dir_local=PosixPath('/Users/tilmann/Documents/Documents/work/hylleraas/hyrun/docs/src/user_guide'), scratch_dir_local=PosixPath('/Users/tilmann/Documents/Documents/work/hylleraas/hyrun/docs/src/user_guide'), data_dir_local=PosixPath('/Users/tilmann/Documents/Documents/work/hylleraas/hyrun/docs/src/user_guide'), submit_dir_local=PosixPath('/Users/tilmann/Documents/Documents/work/hylleraas/hyrun/docs/src/user_guide'), work_dir_remote=None, submit_dir_remote=None, data_dir_remote=None, sub_dir=None, output_folder=None, shell_setup=[], env_vars={'OMP_NUM_THREADS': '$SLURM_CPUS_PER_TASK'}, add_to_path=[], add_to_ld_library_path=[], print_level='critical', log_file=None, logger=<Logger hyset (CRITICAL)>, ntasks=1, ntasks_per_node=None, cpus_per_task=1, memory_per_cpu=None, job_time=datetime.timedelta(0), job_name=None, program=None, launcher=[], args=[], restart=False, output_type=None, dry_run=None, force_recompute=None, wait=None, post_cmd=None, pre_cmd=None, arch_type='remote', connection=ComputeSettingsConnection(host=None, user=None, port=None, config=None, gateway=None, forward_agent=None, connect_timeout=None, connect_kwargs={}, inline_ssh_env=None, auto_connect=True, max_connect_attempts=5, two_factor=False, ssh_socket_path=None, progress_bar=True, connection_type='ssh_fabric', ssh_key_path=None, file_transport='rsync'), scheduler=ComputeSettingsScheduler(scheduler_type='local', scheduler_launcher=[''], slurm_account='nn4654k', modules=[], job_name=None, qos_devel=False, create_symlinks=True, slurm_extra=[]), database=ComputeSettingsDatabase(database_name='mydb', database_type='python', database_opt={}))], outputs=[])\n"
     ]
    }
   ],
   "source": [
    "from hyset.v2 import RunSettings\n",
    "job = Job(tasks=RunSettings(database={'database_name':'mydb'},\n",
    "                            print_level='critical'),\n",
    "          metadata={'name': 'myjob'})\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a4a0b",
   "metadata": {},
   "source": [
    "## Multiple tasks\n",
    "\n",
    "A job can have multiple tasks, i.e. calculations performed consecutively within the same job script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a68ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyset_1 - ERROR : Memory per CPU not set in compute settings.\n"
     ]
    }
   ],
   "source": [
    "rs0 = RunSettings(connection={'host': 'host0'}, print_level='error')\n",
    "job = Job(tasks=[rs0 for _ in range(3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce90aad2",
   "metadata": {},
   "source": [
    "> **Note:** All tasks in a job have to have identical settings for: 1. connection\n",
    "2. scheduler\n",
    "3. database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16bbdc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyset_1 - ERROR : Memory per CPU not set in compute settings.\n",
      "tasks have different parameters\n"
     ]
    }
   ],
   "source": [
    "rs1 = RunSettings(connection={'host': 'host1'})\n",
    "try:\n",
    "    job = Job(tasks=[rs0, rs1])\n",
    "except ValueError:\n",
    "    print('tasks have different parameters')\n",
    "else:\n",
    "    print('all ok')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21134f08",
   "metadata": {},
   "source": [
    "## Database integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ca455",
   "metadata": {},
   "source": [
    "Jobs are the central objects that are used in `hyrun`. Below is a typical example of what happens during a run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d011bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyset.v2 import RunSettings\n",
    "from hytools.file import File\n",
    "from hytools.logger import get_logger\n",
    "from hydb import get_database\n",
    "\n",
    "def hyrun_internal(job):\n",
    "    \"\"\"Stuff that hyrun does internally.\"\"\"\n",
    "    # generate job_script and hash\n",
    "    job.job_script = File(name='job_script',\n",
    "                          content='import sys\\nprint(sys.executable)')\n",
    "    job.set_hash()\n",
    "    # add job to database, as defined in first run_settings\n",
    "    db = get_database(job.tasks[0].database.database_name)\n",
    "    #db.db.truncate()\n",
    "    db_id = db.insert_one(job, immutable={'hash': job.hash}) \n",
    "    if db_id:\n",
    "        job.db_id = db_id\n",
    "    #assert db.insert_one(job, immutable={'hash': job.hash}) == None\n",
    "    # update job\n",
    "    job.job_id = 137\n",
    "    job.status = 'running'\n",
    "    #update db entry\n",
    "    db.update_one(entry=job, db_id=job.db_id)\n",
    "    \n",
    "    return db, job\n",
    "\n",
    "job = Job(tasks=RunSettings(database={'database_name':'mydb'},\n",
    "                            print_level='critical'),\n",
    "          metadata={'name': 'myjob'})\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf1a00",
   "metadata": {},
   "source": [
    "The job is stored as a `dict` in a database and can accessed via the `job.db_id` or by searching for an attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a17218a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "True\n",
      "running\n"
     ]
    }
   ],
   "source": [
    "db, job_updated = hyrun_internal(job)\n",
    "\n",
    "print(db[job_updated.db_id].get('status'))\n",
    "\n",
    "entry = db.search_one(hash=job.hash)\n",
    "print(isinstance(entry, dict))\n",
    "\n",
    "print(entry.get('status'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca084f9e",
   "metadata": {},
   "source": [
    "Finally, the entire `hyrun.job.Job` object can be reconstructed from the database entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b160bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyset_1 - ERROR : Memory per CPU not set in compute settings.\n",
      "\n",
      "-- Job (updated) --\n",
      " Job(job_id=137, db_id=1, job_script=File(name='job_script', content='import sys\\nprint(sys.executable)', path=None, host=None, folder=None), status='running', hash='bc86a255ba412df2ee9b4039ec716865d09dc76d1517e79ae814e85fab898279', metadata={'name': 'myjob'}, tasks=[RunSettings(output_file=None, stdout_file=File(name='stdout.out', content=None, path=PosixPath('stdout.out'), host=None, folder=PosixPath('.')), stderr_file=File(name='stderr.out', content=None, path=PosixPath('stderr.out'), host=None, folder=PosixPath('.')), stdin_file=None, files_to_write=[], files_for_restarting=[], files_to_rename=[], files_to_parse=[], files_to_remove=[], files_to_zip=[], files_to_tar=[], files_to_send=[], files_not_to_transfer=[], data_files=[], tar_all_files=False, zip_all_files=False, use_relative_paths=None, overwrite_files=False, conda_env=None, conda_launcher=[], container_image=None, container_executable=None, container_mounts=None, container_type=None, container_launcher=[], container_args=[], work_dir_container=None, work_dir_local='/Users/tilmann/Documents/Documents/work/hylleraas/hyrun/docs/src/user_guide', scratch_dir_local='/Users/tilmann/Documents/Documents/work/hylleraas/hyrun/docs/src/user_guide', data_dir_local='/Users/tilmann/Documents/Documents/work/hylleraas/hyrun/docs/src/user_guide', submit_dir_local='/Users/tilmann/Documents/Documents/work/hylleraas/hyrun/docs/src/user_guide', work_dir_remote=None, submit_dir_remote=None, data_dir_remote=None, sub_dir=None, output_folder=None, shell_setup=[], env_vars={'OMP_NUM_THREADS': '$SLURM_CPUS_PER_TASK'}, add_to_path=[], add_to_ld_library_path=[], print_level='critical', log_file=None, logger={}, ntasks=1, ntasks_per_node=None, cpus_per_task=1, memory_per_cpu=None, job_time=datetime.timedelta(0), job_name=None, program=None, launcher=[], args=[], restart=False, output_type=None, dry_run=None, force_recompute=None, wait=None, post_cmd=None, pre_cmd=None, arch_type='remote', connection=ComputeSettingsConnection(host=None, user=None, port=None, config=None, gateway=None, forward_agent=None, connect_timeout=None, connect_kwargs={}, inline_ssh_env=None, auto_connect=True, max_connect_attempts=5, two_factor=False, ssh_socket_path=None, progress_bar=True, connection_type='ssh_fabric', ssh_key_path=None, file_transport='rsync'), scheduler=ComputeSettingsScheduler(scheduler_type='local', scheduler_launcher=[''], slurm_account='nn4654k', modules=[], job_name=None, qos_devel=False, create_symlinks=True, slurm_extra=[]), database=ComputeSettingsDatabase(database_name='mydb', database_type='python', database_opt={}))], outputs=[])\n",
      "<class 'hyrun.job.job.Job'>\n"
     ]
    }
   ],
   "source": [
    "# resolve the objects in the db entry\n",
    "job = db.search_one(hash=job.hash, resolve=True)\n",
    "print(f'\\n-- Job (updated) --\\n', job)\n",
    "\n",
    "print(type(job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899b756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
